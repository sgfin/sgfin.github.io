---
layout: post
comments: true
include: true
title:  "All the DAGs from Hernan and Robins' Causal Inference Book"
excerpt: "My attempt to tidy up the DAG treasure trove from Hernan and Robins"
date:   2019-06-19 11:50:00
mathjax: true
---

<style type="text/css" rel="stylesheet">
p {
    width: 100%;
}

th, td, thead, table {
    border: 1px solid #999;
}

tbody tr td:first-child {
  min-width: 12em;
}
</style>


This is my preliminary attempt to organize and present all the DAGs from Miguel Hernan and Jamie Robin's excellent [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/).  So far, I've only done Part I.

I love the Causal Inference book, but sometimes I find it easy to lose track of the variables when I read it.  Having the variables right alongside the DAG makes it easier for me to remember what's going on, especially when the book refers back to a DAG from a previous chapter and I don't want to dig back through the text. Plus, making this was a great exercise!

Again, this page is meant to be fairly raw and only contain the DAGs. If you use it, you might also find it useful to open up [this page](https://sgfin.github.io/2019/06/19/Causal-Inference-Book-Glossary-and-Notes/), which is where I have more traditional notes covering the main concepts from the book. But of course, the text itself has no substitute.


__Table of Contents__:
* TOC
{:toc}


### Refresher: Visual rules of d-separation.

Two variables on a DAG are __d-separated__ if all paths between them are blocked. The following four rules defined what it means to be "blocked."

(This is just meant to be a refresher -- see the second half of this post or Fine Point 6.1 of the text for more definitions.)

| Rule  | Example  |
| :-----------: |:-------------:|
| 1. If there are no variables being conditioned on, a path is blocked if and only if two arrowheads on the path collide at some variable on the path. |  <img src="/assets/hernan_dags/6_1.png" width="175"> <br/><br/> $$L \rightarrow A \rightarrow Y$$ is open. <br/><br/> $$A \rightarrow Y \leftarrow L$$ is blocked at $$Y$$ | 
| 2. Any path that contains a noncollider that has been conditioned on is blocked. |  <img src="/assets/hernan_dags/6_5.png" width="175"> <br/><br/> Conditioning on $$B$$ blocks the path from $$A$$ to $$Y$$.| 
| 3. A collider that has been conditioned on does not block a path |  <img src="/assets/hernan_dags/6_7.png" width="175"> <br/><br/> The path between $$A$$ and $$Y$$ is open after conditioning on $$L$$.| 
| 4. A collider that has a descendant that has been conditioned on does not block a path. |  <img src="/assets/hernan_dags/6_8.png" width="175"> <br/><br/> The path between $$A$$ and $$Y$$ is open after conditioning on $$C$$, a descendant of collider $$L$$.| 

### Refresher: Backdoor criterion

Assuming positivity and consistency, confounding can be eliminated and causal effects are identifiable in the following two settings:

| Rule  | Example  |
| :-----------: |:-------------:|
| 1. No common causes of treatment and outcome. | <img src="/assets/hernan_dags/6_2.png" width="150"> <br/><br/> There are no common causes of treatment and outcome. Hence no backdoor paths need to be blocked. <br/><br/> No confounding; equivalent to a marginally randomized trial.   |
| 2. Common causes are present, but there are enough measured variables to block all colliders. (i.e. No unmeasured confounding.) | <img src="/assets/hernan_dags/6_1.png" width="175"> <br/><br/> Backdoor path through the common cause $$L$$ can be blocked by conditioning on measured covariates (in this case, $$L$$ itself) that are non-descendants of treatment. <br/><br/> There will be no residual confounding after controlling for $$L$$; equivalent to a conditionally randomized trial. |

And now we can finally:

<p style="text-align:center;">
<img src="/assets/hernan_dags/all_the_dags.jpg" width="400">
</p>

### Basics of Causal Diagrams (6.1-6.5)

| DAG   | Example  |  Notes | Page | 
| :-----------: |:-------------:|
|  <img src="/assets/hernan_dags/6_2.png" width="150"> | _Marginally randomized experiment_ <br/><br/>  __A__: Treatment <br/><br/> __Y__: Outcome   |  Arrow doesn't specifically imply protection vs risk, just causal effect. <br/><br/> __Unconditional exchangeability__ assumption means that association implies causation and vice versa. |  I.70  |
|  <img src="/assets/hernan_dags/6_1.png" width="175"> | _Conditionally randomized experiment_ <br/><br/> __L__: Stratification Variable <br/><br/> __A__: Treatment <br/><br/> __Y__: Outcome   | Also equivalent to an _Observational Study_ that assumes A depends on L and on _no other causes of Y_ (else they'd need to be added). <br/><br/> Implies __conditional exchangeability__.  |  I.69-I.70  |
|  <img src="/assets/hernan_dags/6_5.png" width="175"> |  __A__: Aspirin <br/><br/> __B__: Platelet aggregation  <br/><br/> __Y__: Heart Disease   |  $$B$$ is a __mediator__ of $$A$$'s effect on $$Y$$, but conditioning on $$B$$ (e.g by restricting the analysis to people with a specific lab value) blocks the flow of association through the path A $$\rightarrow$$ B $$\rightarrow$$ Y. <br/><br/> Even though $$A$$ and $$Y$$ are _marginally_ associated, they are __conditionally independent__ given $$B$$.  In other words,  A $$\unicode{x2AEB}$$ Y \| B. <br/><br/> Thus, knowing aspirin status gives you no more information once platelets are measured, at least according to this graph. |  I.73  |
|  <img src="/assets/hernan_dags/6_3.png" width="175"> |  __L__: Smoking status <br/><br/> __A__: Carrying a lighter <br/><br/> __Y__: Lung cancer   |  Graph says that carrying a lighter (A) has no causal effect on outcome (Y). <br/> Math form of this assumption is:  Pr[Y^(a=1)=1]=Pr[Y^(a=0)=1] <br/><br/> However, $$A$$ will be spuriously associated with $$Y$$, because path <br/> A $$\leftarrow$$ L $$\rightarrow$$ Y is open to flow from A to Y: they share a common cause. |  I.72  |
|  <img src="/assets/hernan_dags/6_6.png" width="175"> |  __L__: Smoking status <br/><br/> __A__: Carrying a lighter <br/><br/> __Y__: Lung cancer   |  A $$\unicode{x2AEB}$$ Y \| L, because the path A $$\leftarrow$$ L $$\rightarrow$$ Y is closed by conditioning on L. <br/><br/>  Thus, restricting the analysis to either smokers or non-smokers (box around L) means that lighter carrying will no longer be associated with lung cancer.  |  I.74  |
|  <img src="/assets/hernan_dags/6_4.png" width="175"> |  __A__: Genetic predisposition for heart disease <br/><br/> __Y__: Smoking status <br/><br/> __L__: Heart disease   | $$A$$ and $$Y$$ are not marginally associated, because they share no common causes.  (i.e. Genetic risk for heart disease says nothing, in a vaccuum, about smoking status.)  <br/><br/> $$L$$ here is a __collider__ on the path A $$\rightarrow$$ L $$\leftarrow$$ Y, because the two arrows collide on this node. But there is no causal path from $$A$$ to $$Y$$. |  I.73  |
|  <img src="/assets/hernan_dags/6_7.png" width="175"> |  __A__: Genetic predisposition for heart disease <br/><br/> __Y__: Smoking status <br/><br/> __L__: Heart disease   | __Conditioning on the collider__ $$L$$ opens the causal path A $$\rightarrow$$ L $$\leftarrow$$ Y.  <br/><br/>  Put another way, two causes of a given effect generally become associated once we stratify on the common effect. <br/><br/>  In the example, knowing someone with heart disease lacks haplotype A makes it more likely that the individual is a smoker, because, in the absence of $$A$$, it is more likely that some other cause of $$L$$ is present. Or, conversely, the population of non-smokers with heart disease will be enriched for people with haplotype A. Thus, if one restricts the analysis to people with heart disease, he will find a spurious anti-correlation between the haplotype predictive of heart disease and smoking status.  |  I.74  |
|  <img src="/assets/hernan_dags/6_8.png" width="175"> |  __A__: Genetic predisposition for heart disease <br/><br/> __Y__: Smoking status <br/><br/> __L__: Heart disease  <br/><br/> __C__:  Diuretic medication (given after heart disease diagnosis)  | Conditioning on variable $$C$$ __downstream from collider__ $$L$$ also opens up causal path A $$\rightarrow$$ L $$\leftarrow$$ Y. <br/><br/>  Thus, in the example, stratifying on $$C$$ (diuretic status) will induce a spurious relationship between $$A$$ (genetic heart disease risk) and $$Y$$ (smoking status).  |  I.75  |
| _Before matching_: <br/> <img src="/assets/hernan_dags/6_1.png" width="175"><br/><br/> _After matching_:<br/> <img src="/assets/hernan_dags/6_9.png" width="175"> | _Matched analysis_ <br/><br/> __L__: Critical Condition  <br/><br/>  __A__: Heart Transplant  <br/><br/> __Y__: Death <br/><br/> __S__: Selection for inclusion via matching criteria  | In this study design, the average causal effect of $$A$$ on $$Y$$ is computed after matching on $$L$$. <br/><br/> Before matching, $$L$$ and $$A$$ are associated via the path $$L \rightarrow A$$ . <br/><br/> Matching is represented in the DAG through the addition of $$S$$, the selection criteria. The study is obviously restricted to patients that are selected ($$S$$=1), hence we condition on $$S$$. <br/><br/> d-separation rules say that there are now two open paths between $$A$$ and $$L$$ after conditioning on $$S$$:  $$L \rightarrow A$$ and $$L \rightarrow S \leftarrow A$$. This seems to indicate an association between $$L$$ and $$A$$.  However, the point of matching is supposed to be to make sure that $$L$$ and $$A$$ not associated! <br/><br/>  The resolution comes from the observation that $$S$$ has been constructed specifically to induce the distribution of $$L$$ to be the same in the treated ($$A$$=1) and untreated ($$A$$=0) population. This means that the association in $$L \rightarrow S \leftarrow A$$ is of equal magnitude but opposite direction of $$L \rightarrow A$$. Thus there is no net association between $$A$$ and $$L$$. <br/><br/>  This disconnect between the associations visible in the DAG and the associations actually present is an example of __unfaithfulness__, but here it has been introduced by design.  |  I.49 and I.79  |
|  <img src="/assets/hernan_dags/6_10.png" width="175"> |   __R__: Compound treatment (see right) <br/><br/> __A__: Vector of treatment versions $$A( r )$$ (see right) <br/><br/> __Y__: Outcome <br/><br/>  __L__ and __W__: unnamed causes  <br/><br/> __U__: unnmeasured variables  | This is the example the book uses of how to encode compound treatments. <br/><br/> The example compound treatment is as follows: <br/><br/> R=0 corresponds to "exercising _less_ than 30 minutes daily". <br/> R=1 corresponds to "exercising _more_ than 30 minutes daily." <br/><br/> $$A$$ is a vector corresponding to different _versions_ of the treatment, where $$A(r=0)$$ can take on values $$0,1,2,\dots, 29$$ and $$A(r=1)$$ can take on values $$30,31\dots, max$$  <br/><br/> Taken together, we can have a mapping from multiple values $$A( r )$$ onto a single value $$R=r$$. |  I.78  |

###  Effect Modification (6.6)

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
|  <img src="/assets/hernan_dags/6_11.png" width="175"> |  __A__: Heart Transplant <br/><br/> __Y__: Outcome <br/><br/> __M__: Quality of Care. High ($$M=1$$) vs Low ($$M=0$$) | This DAG reflects the assumption that quality of care influences quality of transplant procedure and thus of outcomes, BUT still assumes random assignment of treatment. <br/><br/> Given random assignment, $$M$$ is not strictly necessary but added if you want to use it to stratify. <br/><br/> Causal diagram as such does not distinguish between: <br/> 1. Causal effect of treatment $$A$$ on mortality $$Y$$ is in the same direction in both stratum $$M=1$$ and $$M=0$$. <br/> 2. The causal effect of $$A$$ on $$Y$$ is in the opposite direction in $$M=1$$ vs $$M=0$$. <br/> 3. Treatment $$A$$ as a causal effect on $$Y$$ in one straum of $$M$$ but no effect in other stratum. |  I.80  |
| <img src="/assets/hernan_dags/6_12.png" width="175"> |  __A__: Heart Transplant <br/><br/> __Y__: Outcome <br/><br/> __M__: Quality of Care. High ($$M=1$$) vs Low ($$M=0$$)  <br/><br/> __N__: Therapy Complications  | Same example as above, except assumes that other variables along the path of a modifier can also influence outcomes.   |  I.80  |
| <img src="/assets/hernan_dags/6_13.png" width="175"> |  __A__: Heart Transplant <br/><br/> __Y__: Outcome <br/><br/> __M__: Quality of Care. High ($$M=1$$) vs Low ($$M=0$$)  <br/><br/> __S__: Cost of treatment  | Same example as above, except assumes that the quality of care effects the cost, but that the cost does not influence the outcome. <br/><br/> This is the example of an effect modifier that does not have a causal effect on the outcome, but rather stands as a __surrogate effect modifier__. <br/><br/> Analysis stratifying on $$S$$ -- which is available/objective -- might be used to detect effect modification that actually comes from $$M$$ but is harder to measure.    |  I.80  |
| <img src="/assets/hernan_dags/6_14.png" width="175"> |  __A__: Heart Transplant <br/><br/> __Y__: Outcome <br/><br/> __M__: Quality of Care. High ($$M=1$$) vs Low ($$M=0$$)  <br/><br/> __U__: Place of residence <br/><br/> __P__: Passport-defined nationality  | Example where the surrogate effect modifier (passport) is not driven by the causal effect modifier (quality of care), but rather both are driven by a common cause (place of residence).   |  I.80  |
| <img src="/assets/hernan_dags/6_15.png" width="175"> |  __A__: Heart Transplant <br/><br/> __Y__: Outcome <br/><br/> __M__: Quality of Care. High ($$M=1$$) vs Low ($$M=0$$)  <br/><br/>  __S__: Cost of Care <br/><br/>  __W__: Use of mineral water vs tap |  Example where the surrogate effect modifier (cost) is influenced by _both_ the causal effect modifier (quality) and something spurious. <br/><br/>  If the study were restricted to low-cost hospitals by conditioning on $$S=0$$, then use of mineral water would become associated with medical care $$M$$ and would behave as a surrogate effect modifier. <br/><br/> Addendum: How?  One example might be that conditioned on a low cost, a zero sum situation may arise in which spending more on fancy water means less is being spent on quality care, which could yield an inverse correlation between mineral water and medical quality.  |  I.81  |


### Confounding (Chapter 7)

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
|  <img src="/assets/hernan_dags/7_1.png" width="175"> |  __L__: Being physicially fit <br/><br/> __A__: Working as a firefighter <br/><br/> __Y__: Mortality  | The path $$A \rightarrow Y$$ is a causal path from $$A$$ to $$Y$$. <br/><br/> $$A \leftarrow L \rightarrow Y$$ is a __backdoor path__ between $$A$$ and $$Y$$, mediated by common cause (__confounder__) $$L$$. <br/><br/> Conditioning on $$L$$ will block the backdoor path, induce conditional exchangeability, and allow for causal inference. <br/><br/> _Note_: This is an example of "healthy worker bias."  |  I.83  |
| <img src="/assets/hernan_dags/7_2.png" width="175"> |  __A__: Aspirin <br/><br/> __Y__: Stroke <br/><br/> __L__: Heart Disease  <br/><br/> __U__: Atherosclerosis (unmeasured)  | This DAG is an example of __confounding by indication__ (or __channeling__). <br/><br/> Aspirin will have a confounded association with stroke, both from heart disease ($$L \rightarrow A \rightarrow Y$$), and from atherosclerosis ($$U \rightarrow L \rightarrow A \rightarrow Y$$). <br/><br/> Conditioning on unmeasured $$U$$ is impossible, but there is _no unmeasured confounding_ given $$L$$, so conditioning on $$L$$ is sufficient. |  I.84  |
| <img src="/assets/hernan_dags/7_3.png" width="175"> |  __A__: Exercise <br/><br/> __Y__: Death <br/><br/> __L__: Smoking status  <br/><br/> __U__: Social Factors (unmeasured) or Sublinical Disease (undetected) | Conditioning on $$L$$ is again sufficient to block the backdoor path in this case.  |  I.84  |
| <img src="/assets/hernan_dags/7_4.png" width="175"> |  __A__: Physical activity <br/><br/> __Y__: Cervical Cancer <br/><br/> __L__: Pap smear  <br/><br/> __U_1__: Pre-cancer lesion (unmeasured here) <br/><br/> __U_2__: Health-conscious personality (unmeasured) | Example shows how __conditioning on a collider can induce bias__. <br/><br/>  Adjustment for $$L$$ (e.g. by restricting to negative tests $$L=0$$) will _induce_ bias by opening a backdoor path between $$A$$ and $$Y$$ ($$A \leftarrow U_2 \rightarrow L \leftarrow U_1 \rightarrow Y$$), previously blocked by the collider. This is a case of _selection bias_. <br/><br/> Thus, after conditioning, association between $$A$$ and $$Y$$ would be a mixture of association due to effect of $$A$$ on $$Y$$ and backdoor path. In other words, there is no _unconditional bias_, but there would be a conditional bias for at least one stratum of $$L$$. |  I.88  |
| <img src="/assets/hernan_dags/7_5.png" width="175"> | (Labels not in book)<br/><br/> __A__: Antacid  <br/><br/>  __L__: Heartburn   <br/><br/>  __Y__: Heart attack  <br/><br/>  __U__: Obesity  | A nonconfounding example in which traditional analysis might lead you to adjust for $$L$$, but doing so would _induce a bias_.  |  I.89  |
| <img src="/assets/hernan_dags/7_6.png" width="175"> | __A__: Physical activity  <br/><br/>  __L__: Income   <br/><br/>  __Y__: Cardiovascular disease  <br/><br/>  __U__: Socioeconomic status |  $$L$$ (income) is _not_ a confounder, but is a measurable variable that could serve as a __surrogate confounder__ for $$U$$ (socioeconomic status) and thus could be used to partially adjust for the confounding from $$U$$. <br/><br/> In other words, conditioning on $$L$$ will result in a partial blockage of the backdoor path $$A \leftarrow U \rightarrow Y$$. |  I.90  |
| _Normal DAG_: <br>  <img src="/assets/hernan_dags/7_2.png" width="175"> <br/><br/> _Corresponding SWIG_: <br> <img src="/assets/hernan_dags/7_7.png" width="175"> |  __A__: Aspirin <br/><br/> __Y__: Stroke <br/><br/> __L__: Heart Disease  <br/><br/> __U__: Atherosclerosis (unmeasured) | Represents data from a hypothetical intervention in which all individuals receive the same treatment level $$a$$. <br/><br/> Treatment is split into two sides: <br/> (a) Left side encodes the values of treatment $$A$$ that would have been observed in the absence of intervention (_the natural value of treatment_) <br/> (b) Right side encodes the treatment value under the intervention. <br/>  $$A$$ has no variable into $$a$$ bc $$a$$ is the same everywhere. <br/><br/> Conditional exchangeability $$Y^{a} \unicode{x2AEB} A \| L$$ holds because all paths between $$Y^{a}$$ and $$A$$ are blocked after conditioning on $$L$$. |  I.91  |
| _Normal DAG_: <br>  <img src="/assets/hernan_dags/7_4.png" width="175"> <br/><br/> _Corresponding SWIG_: <br> <img src="/assets/hernan_dags/7_8.png" width="175"> |  __A__: Physical activity <br/><br/> __Y__: Cervical Cancer <br/><br/> __L__: Pap smear  <br/><br/> __U_1__: Pre-cancer lesion (unmeasured here) <br/><br/> __U_2__: Health-conscious personality (unmeasured) |  Here, marginal exchangeability $$Y^{a} \unicode{x2AEB} A $$ holds because, on the SWIG, all paths between $$Y^{a}$$ and $$A$$ are blocked without conditioning on $$L$$. <br/><br/> Conditional exchangeability $$Y^{a} \unicode{x2AEB} A \| L$$ does not hold because, on the SWIG, the path $$Y^{a} \leftarrow U_1 \rightarrow L \leftarrow U_2 \rightarrow A$$ is open when the collider $$L$$ is conditioned on. <br/><br/>  Taken together, marginal $$A-Y$$ association is causal but conidtional association $$A-Y$$ given $$L$$ is not. |  I.91  |
| _Normal DAG_: <br>  <img src="/assets/hernan_dags/7_9.png" width="175"> <br/><br/> _Corresponding SWIG_: <br> <img src="/assets/hernan_dags/7_10.png" width="175"> | (Example labels not in book)<br/><br/> __A__: Statins  <br/><br/> __Y__: Coronary artery disease <br/><br/> __L__: HDL/LDL   <br/><br/> __U__: Race | In this example, the SWIG is used to highlight a failure of the DAG to provide conditional exchangeability $$Y^{a} \unicode{x2AEB} A \| L$$. <br/><br/> In the SWIG, the factual variable $$L$$ is replaced by the counterfactual variable $$L^{a}$$.  In this SWIG, counterfactual exchangeability $$Y^{a} \unicode{x2AEB} A \| L_{a}$$ holds, since $$L^{a}$$ blocks the paths from $$Y^{a}$$ to $$A$$. But $$L$$ is not even on the graph, so we can't conclude $$Y^{a} \unicode{x2AEB} A \| L$$ holds.  <br/><br/> The problem being highlighted here is that $$L$$ is a _descendent_ of the treatment $$A$$ blocking the path to $$Y$$. <br/><br/> In contrast, if the arrow from $$A$$ to $$L$$ didn't exist, $$L$$ would not be a descendent of $$A$$ and adjusting for $$L$$ _would_ eliminate all bias, even if $$L$$ were still in the future of $$A$$. Thus, confounders are allowed to be in the future of the treatment, they just can't be descendents. |  I.92 |
| <img src="/assets/hernan_dags/7_11.png" width="175"> | __A__: Aspirin  <br/><br/> __Y__: Blood Pressure   <br/><br/>  __U__: History of heart disease (unmeasured) <br/><br/> __C__: Blood pressure right before treatment ("placebo test" aka "negative outcome control")  |  This example was used to show __difference-in-difference__ and __negative outcome controls__. <br/><br/> The idea: We cannot compute the effect of $$A$$ on $$Y$$ via standardization or IP weighting because there is unmeasured confounding. Instead, we first measure the ("negative") outcome $$C$$ right before treatment. Obviously $$A$$ has no effect on $$C$$, but we can assume that $$U$$ will have the same confounding effect on $$C$$ that it has on $$Y$$. <br/><br/> As such, we take the effect in the treated to be the effect of $$A$$ on $$Y$$ (treatment effect + confounding effect) _minus_ the effect of $$A$$ on $$C$$ (confounding effect). This is the difference-in-differences. <br/><br/> Negative outcome controls are sometimes used to try to _detect_ confounding. |  I.95  |
| <img src="/assets/hernan_dags/7_12.png" width="175"> | (No example labels in text) <br/><br/> __A__: Aspirin  <br/><br/> __M__: Platelet Aggregation <br/><br/> __Y__: Heart Attack <br/><br/> __U__: High Cardiovascular Risk | This example is to demonstrate the __frontdoor criterion__ (see notes or page I.96 for more details). <br/><br/> Given this DAG, it is impossible to directly use standardization or IP weighting, because the unmeasured variable $$U$$ is necessary to block the backdoor path between $$A$$ and $$Y$$. <br/><br/> However, the frontdoor adjustment can be used because: <br/> (i) the effect of $$A$$ on $$<$$ can be computed without confounding, and <br/> (ii) the effect of $$M$$ on $$Y$$ can be computed because $$A$$ blocks only the backdoor path. <br/><br/> Hence, __frontdoor adjustment__ can be used. |  I.95  |

__Some additional (but structurally redundant) examples of confounding from chapter 7__:

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
|  <img src="/assets/hernan_dags/7_3.png" width="175"> |  __A__: Exercise <br/><br/> __Y__: Death <br/><br/> __L__: Smoking status  <br/><br/> __U__: Social Factors (unmeasured) or Sublinical Disease (undetected) |  _Subclinical disease_ could also result both in lack of exercise $$A$$ and increased risk of a clinical diseae $$Y$$. This is an example of __reverse causation__. |  I.84  |
| <img src="/assets/hernan_dags/7_3.png" width="175"> |  __A__: Gene being tested <br/><br/> __Y__: Trait <br/><br/> __L__: Different gene in LD with gene A   <br/><br/> __U__: Ethnicity  | _Linkage disequilibrium_ can drive spurious associations between gene $$A$$ and trait $$Y$$ if the true causal gene $$L$$ is in LD with $$A$$ in patients with ethnicity $$U$$. |  I.84  |
| <img src="/assets/hernan_dags/7_3.png" width="175"> |  __A__: Airborne particulate matter <br/><br/> __Y__: Coronary artery disease <br/><br/> __L__: Other pollutants  <br/><br/> __U__: Weather conditions  | _Environmental exposures_ often co-vary with the weather conditions.  As such, certain pollutants $$A$$ may be spuriously associated with outcome $$Y$$ simply because the weather drives them to co-occur with $$L$$.  |  I.84  |


### Selection Bias (Chapter 8)

__Note__:  While randomization eliminates _confounding_, it does not eliminate _selection bias_.  All of the issues in this section apply just as much to prospective and/or randomized trials as they do to observational studies.

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
| <img src="/assets/hernan_dags/8_1.png" width="175"> | __A__: Folic Acid supplements  <br/><br/> __Y__: Cardiac Malformation <br/><br/> __C__: Death before birth  | In this example, we assume folic acid supplements _decrease_ mortality by reducing non-cardiac malformations, cardiac malformatins _increase_ mortality, and cardiac malformations _increase_ mortality.  <br/><br/> Study restricted participants to fetuses who survived until birth ($$C=0$$).  <br/><br/> Two sources of association between treatment and outcome: <br/> 1. Open path $$A \rightarrow Y$$, the causal effect. <br/> 2. Open path $$A \rightarrow C \leftarrow Y$$ linking $$A$$ and $$Y$$ due to __conditioning on common effect (collider)__ $$C$$.  This is the __selection bias__, specifically, __selection bias under the null__.  <br/><br/> The selection bias eliminates ability to make causal inference. If analysis were not conditioned on $$C$$, causal inference would be valid.  | I.97 |
| <img src="/assets/hernan_dags/8_2.png" width="175"> | __A__: Folic Acid supplements  <br/><br/> __Y__: Cardiac Malformation <br/><br/> __C__: Death before birth <br/><br/>  __S__: Parental Grief  |  This example is the same as the above, except we consider if the researchers instead conditioned on the __effect of the collider__, namely $$S$$, parental grief. <br/><br/> This is _still_ __selection bias__, $$A \rightarrow C \leftarrow Y$$ linking $$A$$ is open, and association is not causation.  | I.98 |
| <img src="/assets/hernan_dags/8_3.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_5.png" width="175"> | (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/>   __A__: Antiretroviral treatment  <br/><br/> __Y__: 3-year death <br/><br/> __C__: Censoring from study or Missing Data <br/><br/> __U__: High immunosuppresion (unmeasured) <br/><br/>  __L__: Symptoms, CD4 count, viral load (unmeasured) <br/><br/>  ------------ <br/><br/> __W__: Lifestyle, personality, educational variables (unmeasured) |  Figure 8.3:<br/> In this example, individuals with high immunosuppresion -- in addition to having higher risk of death -- manifest worse physical symptoms that mediates censoring from the study.  Treatment also worsens side effects, which increases censoring, as well. <br/><br/>  $$C$$ is conditioned upon, because those are the only ones who actually contribute data to the study. <br/><br/> Per d-separation, $$A \rightarrow C \leftarrow L \leftarrow U \rightarrow Y$$ is open due to conditioning on $$C$$, allowing association to flow from $$A$$ to $$Y$$ and killing causal inference.  <br/><br/> Note: This is a transformation of figure 8.1, except instead of $$Y$$ acting directly on $$C$$, we have $$U$$ acting on both $$Y$$ and $$C$$. <br/><br/> Intuition for the bias: if a treated individual with treatment-induced side effects does not drop out ($$C=0$$), this implies that he probably didn't have high immunosuppresion $$U$$, and low immunosuppresion means better outcomes. Hence, there is probably an inverse association between $$A$$ and $$U$$ among those that don't drop out. <br/><br/> This is an example of __selection bias__ that arises from __conditioning on a censoring variable that is a comon effect of both treatment $$A$$ and cause $$U$$ of the outcome $$Y$$.__ <br/><br/>  ------------ <br/><br/> Figure 8.5 is the same idea, except it notes that sometimes additional unmeasured variables may contribute to both treatment and censoring. | I.98 |
| <img src="/assets/hernan_dags/8_4.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_6.png" width="175"> |  (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/>   __A__: Antiretroviral treatment  <br/><br/> __Y__: 3-year death <br/><br/> __C__: Censoring from study or Missing Data <br/><br/> __U__: High immunosuppresion (unmeasured) <br/><br/>  __L__: Symptoms, CD4 count, viral load (unmeasured) <br/><br/>  ------------ <br/><br/> __W__: Lifestyle, personality, educational variables (unmeasured) | Same example as 8.3/8.5, except we assume that treatment (especially prior treatment) has direct effect on symptoms $$L$$. <br/><br/> Restricting to uncensored individuals still implies conditioning on a __common effect__ $$C$$ of both $$A$$ and $$U$$, introducing an association between treatment and outcome. <br/><br/> (__Note__: Unlike in Figure 8.3/8.5, even if we had access to $$L$$, stratification is impossible in these DAGs, because while conditioning on $$L$$ blocks the backdoor path from $$C$$ to $$Y$$, it also opens the backdoor path $$A \rightarrow L \leftarrow U \rightarrow Y$$ because $$L$$ is a collider on that path. IP-weighting, in contrast, could work here.  See page I.108 in section 8.5 for a discussion.)   | I.98 |
| <img src="/assets/hernan_dags/8_7.png" width="175"> | __A__: Physical activity  <br/><br/> __Y__: Heart Disease <br/><br/> __C__: Becoming a firefighter <br/><br/>  __L__: Parental socioeconomic status <br/><br/> __U__: Interest in physical activites (unmeasured) | The goal of this example is to show that while _confounding_ and _selection bias_ are distinct, they can often become functionally the same; this is why some call selection bias "confounding". <br/><br/> Assume that -- unknown to the investigators -- $$A$$ does not cause $$Y$$.  Parental SES $$L$$ affects becoming a firefighter $$C$$, and, through childhood diet, heart disease risk $$Y$$. But we assume that $$L$$ doesn't affect $$A$$. Attraction to physical activity $$U$$ affects being physically active $$A$$ and being a firefighter $$C$$, but not $$Y$$. <br/><br/> Per these assumptions, there is _no confounding_, bc no common causes of $$A$$ and $$Y$$. However, restricting the study to firefighters ($$C=0$$), induces a _selection bias_ that can be eliminated by adjusting for $$L$$. Thus, some economists would call $$L$$ a "confounder" because adjusting for it eliminates the bias.  | I.101 |
| <img src="/assets/hernan_dags/8_8.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_9.png" width="175"> | __A__: Heart Transplant  <br/><br/> __Y_1__: Death at time point 1 <br/><br/> __Y_2__: Death at time point 2 <br/><br/>  __U__: Protective genetic haplotype (unmeasured) | The purpose of this example is to show the potential for selection bias in _time-specific hazard ratios_. <br/><br/> The example depicts a _randomized experiment_ representing the effect of heart transplant on risk of death at two time points, for which we assume the true causal DAG is figure 8.8. <br/><br/> In figure 8.8, we assume that $$A$$ only directly affects death at the first time point and that $$U$$ decreases risk of death at all times but doesn't affect treatment. <br/><br/> In this circumstance, the unconditional associated risk ratios are not confounded.  In other words, $$aRR_{AY_1} = \frac{[Y_{1}\|A=1]}{[Y_{1}\|A=0]}$$ and  $$aRR_{AY_2} = \frac{[Y_{2}\|A=1]}{[Y_{2}\|A=0]}$$ are unbiased and valid for causal inference. <br/><br/> However, trying to compute time-specific hazard ratios is risky. The process is valid at time point 1 ($$aRR_{AY_1}$$ is the same as above), but the hazard ratio at time point 2 is inherently conditional on having survived at time point 1: $$aRR_{AY_2\|Y_{1}=0} = \frac{[Y_{2}\|A=1,Y_{1}=0]}{[Y_{2}\|A=0,Y_{1}=0]}$$. Since $$U$$ affects survival at time point 1, however, this induces a selection bias that opens a path $$A\rightarrow Y_{1} \leftarrow U \rightarrow Y_{2}$$ beteween $$A$$ and $$Y_2$$.  <br/><br/> If we could condition on $$U$$, then $$aRR_{AY_2\|Y_{1}=0,U}$$ would be valid for causal inference. But we can't, so conditioning on $$Y_{1}=0$$ makes the DAG functionally equivalent to Figure 8.9.  This issue is relevant to observational and randomized experiments over time. | I.102 |
| <img src="/assets/hernan_dags/8_3.png" width="175">  | (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/>   __A__: Wasabi consumption (randomized)  <br/><br/> __Y__: 1-year death <br/><br/> __C__: Censoring   <br/><br/>  __L__: Heart Disease <br/><br/> __U__: Atherosclerosis (unmeasured) | This example is of an __RCT with censoring__. We imagine that there was in reality an equal number of deaths in treatment and control, but there was higher censoring ($$C=1$$) among patients with heart disease and higher censoring among the wasabi arm.  As such, we observe more deaths in the wasabi group than in control. Thus, we see a __selection bias__ due to __conditioning on common effect__ $$C$$. <br/><br/> There are _no common causes_ of $$A$$ and $$Y$$ -- expected in a marginally randomized experiment -- so there is no need to adjust for _confounding_ per se.  However, there is a common cause $$U$$ of both $$C$$ and $$Y$$, inducing a backdoor path $$C \leftarrow L \leftarrow U \rightarrow Y$$.  As such, conditioning on non-censored patients $$C=0$$ means we have a selection bias that turns $$U$$ functionally into a confounder. $$U$$ is unmeasured, but the backdoor criterion says that __adjusting for $$L$$__ here blocks the backdoor path. <br/><br/> The takeaway here is that __censoring or other selection changes the causal question__, and turns the counterfactual outcome into $$Y^{a=1,c=0}$$ -- the outcome of receiving the treatment _and_ being uncensored.  The relevant causal risk ratio, for example, is thus now $$\frac{E[Y^{a=1,c=0}]}{E[Y^{a=0,c=0}]}$$ -- "the risk if everyone had been treated and was uncensored" vs "the risk if everyone were untreated and remained uncensored." In this sense, __censoring is another treatment__.  | I.105 |
| <img src="/assets/hernan_dags/8_12.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_13.png" width="175">  | __A__: Surgery  <br/><br/> __Y__: Death <br/><br/> __E__: Genetic hapltype <br/><br/>  ------------ <br/><br/> _Death subsplit by causes_: (not recorded) <br/><br/> __Y_A__: Death from tumor <br/><br/>  __Y_E__: Death from heart attack <br/><br/> __Y_A__: Death from other causes|  In this example, Figure 8.12, surgery $$A$$ and haplotype $$E$$ are: <br/> (i) marginally independent (i.e. haplotype doesn't affect probability of receiving surgery), and <br/> (ii) associated conditionally on $$Y$$ (i.e. probability of receiving surgery _does_ vary by haplotype within at least one stratum of the haplotype). <br/><br/> The purpose of this example is to show that despite this fact, situations exist in which $$A$$ and $$E$$ remain conditionally independent within _some_ haplotypes. <br/><br/> Key idea here is that to recognize that if you split death into different causes (even if this isn't recorded), $$A$$ and $$E$$ affect different sub-causes in different ways (specifically, $$A$$ removes tumor, and $$E$$ prevents heart attack). <br/><br/> Arrows from $$Y_{A}$$, $$Y_{E}$$, and $$Y_{O}$$ to $$Y$$ are deterministic, and $$Y=0$$ if and only if $$Y_{A} = Y_{E}=Y_{O}=0$$, so conditioning on $$Y_{0}=0$$ implicitly conditions the other $$Y$$s to zero. This also blocks the path between $$A$$ and $$E$$, since it is conditioning on non-colliders $$Y_{A}$$, $$Y_{E}$$, and $$Y_{O}$$. <br/><br/> In contrast, conditioning on $$Y=1$$ is compatible with any combination of $$Y_{A}$$, $$Y_{E}$$, and $$Y_{O}$$ being equal to 1, so the path between $$A$$ and $$E$$ is not blocked. <br/><br/> The ability to break the conditional probability of survival down in this way is an example of a __multiplicative survival model__. | I.105 |
| <img src="/assets/hernan_dags/8_14.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_15.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_16.png" width="175"> | __A__: Surgery  <br/><br/> __Y__: Death <br/><br/> __E__: Genetic hapltype <br/><br/>  ------------ <br/><br/> _Death subsplit by causes_: (not recorded) <br/><br/> __Y_A__: Death from tumor <br/><br/>  __Y_E__: Death from heart attack <br/><br/> __Y_A__: Death from other causes |  Same setup as in the examples of Figure 8.12 and 8.13.  However, in all of these DAGs, $$A$$ and $$E$$ affect survival thrugh a common mechanism, either directly or indirectly.  In such cases, $$A$$ and $$E$$ are dependent in _both_ strata of $$Y$$. <br/><br/> Taken together with the example above, the point is that __conditioning on a collider _always_ induces an association between its causes, but that this association _may_ or _may not_ be restricted to certain levels of the common effect__.   | I.105 |


__Some additional (but structurally redundant) examples of selection bias from chapter 8__:

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
|  <img src="/assets/hernan_dags/8_4.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_6.png" width="175">  | (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/> __A__: Occupational exposure  <br/><br/> __Y__: Mortality <br/><br/> __C__: Being at Work <br/><br/> __U__: True health status <br/><br/>  __L__: Blood tests and physical exam ------------ <br/><br/> __W__: Exposed jobs are eliminated and workers laid off  | (_Note_: DAGS 8.3/8.5 work just as well, here.) <br/><br/> __Healthy worker bias__: <br/> If we restrict a factory cohort study to those individuals who are actually at work, we miss out on the people that are not working due to either: <br> (a) disability caused by exposure, or <br> (b) a common cause of not working and not being exposed. | I.99 |
|  <img src="/assets/hernan_dags/8_3.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_5.png" width="175">  | (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/> __A__: Smoking status  <br/><br/> __Y__: Coronary heart disease <br/><br/> __C__: Consent to participate <br/><br/> __U__: Family history <br/><br/>  __L__: Heart disease awareness ------------ <br/><br/> __W__: Lifestyle  | (_Note_: DAGS 8.4/8.6 work just as well, here.) <br/><br/> __Self-selection bias or Volunteer bias__: <br/> Under any of the above structures, if the study is restricted to people who volunteer or choose to participate, this can induce a selection bias. | I.100 |
|  <img src="/assets/hernan_dags/8_3.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/8_5.png" width="175">  | (_Note: Missing arrow: $$A \rightarrow Y$$_ ) <br/><br/> __A__: Smoking status  <br/><br/> __Y__: Coronary heart disease <br/><br/> __C__: Consent to participate <br/><br/> __U__: Family history <br/><br/>  __L__: Heart disease awareness ------------ <br/><br/> __W__: Lifestyle | (_Note_: DAGS 8.4/8.6 work just as well, here.) <br/><br/> __Selection affected by treatment received before study entry__: <br/> Generalization of self-selection bias. Under any of the above structures, if the treatment takes place before the study selection or includes a pre-study component, a selection bias can arise. <br/><br/> Particularly high-risk in studies that look at lifetime exposure to something in middle-aged volunteers.  <br/><br/> Similar issues often arise with confounding if confounders are only measured during the study.  | I.100 |


### Measurement Bias (Chapter 9)

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
| <img src="/assets/hernan_dags/9_1.png" width="175"> | __A__: True Treatment <br/><br/> <strong>A*</strong>: Measured treatment <br/><br/> __Y__: True Outcome  <br/><br/> __U_A__: Measurement error  | This DAG is simply to demonstrate how the __measured treatment__ $$A^{*}$$ (aka "measure" or "indicator") recorded in the study is different from the _true_ treatment (aka "construct").  It also introduces $$U_{A}$$, the __measurement error__ variable, which encodes all the factors other than $$A$$ that determine $$A^{*}$$  <br/><br/> _Note_:  $$U_{A}$$ and $$A^{*}$$ were unnecessary in discussions of _confounding_ or _selection bias_ because they are not a part of a backdoor path and no variables are conditioned on them. | I.111 |
| <img src="/assets/hernan_dags/9_2.png" width="175"> | __A__: True Treatment <br/><br/> <strong>A*</strong>: Measured treatment  <br/><br/> __Y__: True Outcome <br/><br/> <strong>Y*</strong>: Measured outcome  <br/><br/> __U_A__: Measurement error for A <br/><br/> __U_Y__: Measurement error for Y | This DAG adds in the notion of imperfect measurement for the outcome as well as the treatment.   <br/><br/>  Note that there is still no _confounding_ or _selection bias_ at play here, so __measurement bias__ or __information bias__ is the only thing that would break the link between association and causation. <br/><br/> Figure 9.2 is an example of a DAG with __independent nondifferential error__.  | I.112 |
| <img src="/assets/hernan_dags/9_3.png" width="175"> | __A__: Drug use <br/><br/> <strong>A*</strong>: Recorded history of drug use  <br/><br/> __Y__: Liver toxicity <br/><br/> __Y*__: Liver lab values  <br/><br/> __U_A__: Measurement error for A <br/><br/> __U_Y__: Measurement error for Y <br/><br/> __U_AY__: Measurement error affecting A and Y (e.g memory and language gaps during interview) |  In Figure 9.2 above, $$U_{A}$$ and $$U_{Y}$$ are independent according to d-separation, because the path between them is blocked by colliders. Independent errors could include EHR data entry errors that occur by chance, technical errors at a lab, etc. <br/><br/> In this figure, we add $$U_{AY}$$ to note the existence of _dependent_ errors. For example, communication errors that take place during an interview with a patient could effect both recorded drug use and previous recorded lab tests.  <br/><br/> Figure 9.3 is an example of __dependent nondifferential error__.  | I.112 |
| <img src="/assets/hernan_dags/9_4.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/9_6.png" width="175"> | __A__: Drug use <br/><br/> <strong>A*</strong>: History of drug use per patient interview  <br/><br/> __Y__: Dementia <br/><br/> __Y*__: Dementia diagnosis  <br/><br/> __U_A__: Measurement error for A <br/><br/> __U_Y__: Measurement error for Y  <br/>__________ <br/> __U_AY__:  Measurement error affecting A and Y |  __Recall bias__ is one example of how the _true outcome_ can bias _treatment measurement error_. <br/><br/> In this example, patients with dementia are less able to effectively communicate, so true cases of the disease are more likely to have faulty medical histories. <br/><br/> Another example of _recall bias_ could be in a study of the effect of alcohol use during pregancy $$A$$ on birth defects $$Y$$, if the alcohol intake is measured by recall after delivery. Bad medical outcomes, especially ones like complicated births, often affect patient recall and patient reporting. <br/><br/>  Figure 9.4 is an example of __independent differential measurement error__. <br/><br/> Adding dependent errors such as a faulty interview makes Figure 9.6 an example of __dependent differential error__.  | I.113 |
| <img src="/assets/hernan_dags/9_5.png" width="175"> <br/><br/><br/> <img src="/assets/hernan_dags/9_7.png" width="175"> | __A__: Drug use <br/><br/> <strong>A*</strong>: Recorded history of drug use  <br/><br/> __Y__: Liver toxicity <br/><br/> __Y*__: Liver lab values  <br/><br/> __U_A__: Measurement error for A <br/><br/> __U_Y__: Measurement error for Y <br/>__________ <br/> __U_AY__:  Measurement error affecting A and Y   | An example of _true treatment_ affecting the _measurement error of the outcome_ could also arise in the setting of drug use and liver toxicity. <br/><br/> For example, if a doctor finds out a patient has a drug problem, he may start monitoring the patients liver more frequently, and become more likely to catch aberrant liver lab values and record them in the EHR. <br/><br/>  Figure 9.5 is an example of __independent differential measurement error__. <br/><br/> Adding dependent errors such as a faulty interview makes Figure 9.7 an example of __dependent differential error__. | I.113 |
| <img src="/assets/hernan_dags/9_8.png" width="175"> <br/><br/> <img src="/assets/hernan_dags/7_5.png" width="175"> | __A__: Drug use  <br/><br/> __Y__: Liver toxicity <br/><br/> __L__: History of hepatitis  <br/><br/> <strong>L*</strong>: Measured history of hepatitis | This example demonstrates __mismeasured confounders__. <br/><br/> Controlling for $$L$$ in Figure 9.8 would be sufficient to allow for causal inference. However, if $$L$$ is imperfectly measured -- say, because it was retrospectively recorded from memory -- then the standardized or IP-weighted risk ratio based on $$L^{*}$$ will generally differ from the true causal risk ratio.  <br/><br/> A cool observation is that since noisy measurement of confounding can be thought of as unmeasured confounding, Figure 9.9 is actually equivalent to Figure 7.5:  $$L^{*}$$ is essentially a _surrogate confounder_ (like Figure 7.5's $$L$$) for an unmeasured actual confounder (Figure 7.5's $$U$$ playing the role of Figure 9.9's $$L$$). Hence, controlling for $$L^{*}$$ will be better than nothing but still flawed. | I.114 |
| <img src="/assets/hernan_dags/9_9.png" width="175">  | __A__: Aspirin <br/><br/> __Y__: Stroke <br/><br/> __L__: Heart Disease  <br/><br/> __U__: Atherosclerosis (unmeasured) <br/><br/> <strong>L*</strong>: Measured history of heart disease | Figure 9.9 is the same idea as Figure 9.8:  Even though controlling for $$L$$ _would_ be sufficient, a mismatched $$L^{*}$$ is insufficient to block the backdoor path in general. <br/><br/> Another note here is that __mismeasurement of confounders can result in apparent effect modification__. For example, if all participants who reported a history of heart disease ($$L^{*}=1$$) and half the participants who reported no such history ($$L^{*}=0$$) actually had heart disease, then stratifying on ($$L^{*}=1$$) would eliminate all confounding in that stratum, but statifying on ($$L^{*}=0$$) would fail to do so. Thus one could detect a spurious assocation in ($$L^{*}=0$$) but not in ($$L^{*}=1$$) and falsely conclude that $$L^{*}$$ is an effect modifier. (See discussion on I.115.)  | I.114 |
| <img src="/assets/hernan_dags/9_10.png" width="175">  | __A__: Folic Acid supplements  <br/><br/> __Y__: Cardiac Malformation <br/><br/> __C__: Death before birth  <br/><br/> __C*__: Death records | __Conditioning on a mismeasured collider induces a selection bias__, because $$C^{*}$$ is a common effect of treatment $$A$$ and outcome $$Y$$. | I.115 |
| <img src="/assets/hernan_dags/9_11.png" width="175"> <br/><br/> <img src="/assets/hernan_dags/9_12.png" width="175">  | __Z__: Assigned treatment  <br/><br/> __A__: Heart Transplant  <br/><br/> __Y__: 5-year Mortality <br/><br/> (Ignore __U__ here) | Figure 9.11 is an example of an __intention-to-treat__ RCT. <br/><br/> ITT RCT's can be almost thought of as an RCT with a potentially _misclassified treatment_. However, unlike a misclassifed treatment, the treatment assignment $$Z$$ has a causal effect on the outcome $$Y$$, both <br/> (a) by influencing the actual treatment $$A$$, and <br/>(b) by influencing study participants who know what $$Z$$ is and change their behavior accordingly.<br/> Hence, the causal effect of $$Z$$ on $$Y$$ depends on the strength of the arrow $$Z \rightarrow Y$$, the arrow $$Z \rightarrow A$$, and the arrow $$A \rightarrow Y$$.  <br/><br/>  Double-blinding attempts to remove $$Z \rightarrow Y$$ (Figure 9.12). | I.115 |
| <img src="/assets/hernan_dags/9_11.png" width="175">  | __Z__: Assigned treatment  <br/><br/> __A__: Heart Transplant  <br/><br/> __Y__: 5-year Mortality <br/><br/> __U__: Illness Severity (unmeasured) | By including $$U$$, we are considering the fact that in an IIT study, severe illness (or other variables) contribute to some patients to seek out different treatment than they've been assigned. <br/><br/>  Note that there is a backdoor path $$A \leftarrow U \rightarrow Y$$ and thus __confounding for the effect of $$A$$ on $$Y$$__, requiring adjustment. <br/><br/> However, there is __no confounding of $$Z$$ and $$Y$$__, and thus no need for adjustment. <br/><br/> This explains why the __intention-to-treat effect__ is often estimated in lieu of the __per-protocol effect__.  <br/><br/> Taken together, ___per-protocol effect_ brings with it unmeasured confounding__, and ___IIT_ brings risk of misclassification bias__. So one needs to trade these off when deciding which to use. (Full discussion below and on I.120)| I.115 |
| <img src="/assets/hernan_dags/9_13.png" width="175">  | __Z__: Assigned treatment  <br/><br/> __A__: Heart Transplant  <br/><br/> __Y__: 5-year Mortality <br/><br/> __U__: Illness Severity (unmeasured) <br/><br/> __L__: Measured factors that mediate U  | This example is of a __as-treated analysis__, a type of per-protocol analysis <br/><br/> _As-treated_ includes _all patients_ and compares those treated ($$A=1$$) vs not treated ($$A=0$$), independent of their assignment $$Z$$.  <br/><br/> As-treated analyses are _confounded_ by $$U$$, and thus depend entirely on whether they can accurately adjust for measurable factors $$L$$ to block the backdoor paths between $$A$$ and $$Y$$. | I.118 |
| <img src="/assets/hernan_dags/9_14.png" width="175">   | __Z__: Assigned treatment  <br/><br/> __A__: Heart Transplant  <br/><br/> __Y__: 5-year Mortality <br/><br/> __U__: Illness Severity (unmeasured) <br/><br/> __L__: Measured factors that mediate U <br/><br/> __S__: Selection filter (A=Z) | This example is of a __conventional per-protocol analysis__, a second method to measure per-protocol effect.  <br/><br/>  Conventional per-protocol analyses limit the population to those who adhered to the study protocol, subsetting to those for whom $$A=Z$$. <br/><br/>  This method induces a _selection bias_ on $$A=Z$$, and thus still requires adjustment on $$L$$.  | I.118 |


__Some additional (but structurally redundant) examples of measurement bias from chapter 9:__

| DAG  | Example  |  Notes | Page | 
| :-----------: |:-------------:|
| <img src="/assets/hernan_dags/9_4.png" width="175"> | __A__: Drug use <br/><br/> <strong>A*</strong>: Recorded history of drug use  <br/><br/> __Y__: Liver toxicity <br/><br/> __Y*__: Liver lab values  <br/><br/> __U_A__: Measurement error for A <br/><br/> __U_Y__: Measurement error for Y  |  __Reverse causation bias__ is another example of how the _true outcome_ can bias _treatment measurement error_. <br/><br/> In this example, liver toxicity worsens clearance of drugs from the body, which could affect blood levels of the drugs.| I.112 |






